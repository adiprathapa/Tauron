{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tauron — ML Pipeline\n",
    "**Cornell Digital Ag Hackathon · Feb 27–Mar 1, 2026**\n",
    "\n",
    "---\n",
    "\n",
    "### The model\n",
    "One GraphSAGE network with a GRU temporal layer on top. It takes the contact graph as input\n",
    "and outputs one risk score per cow per disease (mastitis, BRD, lameness) for the next 48 hours.\n",
    "Multi-head output layer — same graph, same weights, three output neurons.\n",
    "\n",
    "### The key innovation\n",
    "When Cow A's health signals degrade, her neighbours' risk scores update through message passing —\n",
    "even if they look fine right now. A threshold alert or LSTM watching each cow in isolation\n",
    "structurally cannot do this.\n",
    "\n",
    "### The data\n",
    "Base: **Wageningen University dairy sensor dataset** (Rutten et al. 2017 — *Computers and Electronics\n",
    "in Agriculture* 132:108–118. DOI: 10.1016/j.compag.2016.11.009).  \n",
    "Sensors: ear-tag device logging **activity, rumination, feeding activity, ear temperature** hourly  \n",
    "on 400 cows over one year on a Dutch dairy farm.\n",
    "\n",
    "Because the dataset does not include labeled disease outbreak events, we **synthetically inject**\n",
    "disease events — programmatically marking cows as sick and walking contagion forward through the\n",
    "contact graph using documented transmission rates from published epidemiology literature.\n",
    "\n",
    "```\n",
    "01 DATA       →  02 GRAPH BUILD  →  03 SYNTHETIC LABELS  →  04 TRAIN  →  05 PREDICT + XAI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 · Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, random, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Device : {DEVICE}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "\n",
    "DATA_DIR  = Path('data')\n",
    "MODEL_DIR = Path('models')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 01 · Wageningen Dataset\n",
    "\n",
    "**Paper:** Rutten CJ et al. (2017). *Sensor data on cow activity, rumination, and ear temperature\n",
    "improve prediction of the start of calving in dairy cows.*  \n",
    "Computers and Electronics in Agriculture 132:108–118.  \n",
    "https://doi.org/10.1016/j.compag.2016.11.009  \n",
    "https://research.wur.nl/en/publications/sensor-data-on-cow-activity-rumination-and-ear-temperature-improv/\n",
    "\n",
    "**Sensor:** SensOor ear-tag — logs activity, rumination, feeding, and ear temperature hourly  \n",
    "**Scale:** 400 cows · 1 year · Dutch dairy farm\n",
    "\n",
    "> **To use the real dataset:** contact corresponding author C.J. Rutten via the Research@WUR page\n",
    "> or check supplementary materials at the ScienceDirect article. Once obtained, save the file as\n",
    "> `data/wageningen.csv` with columns matching `WAGENINGEN_COLS` below and set `USE_REAL_DATA = True`.\n",
    "\n",
    "Until then the synthetic generator below reproduces the exact statistical profile of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Wageningen sensor schema ─────────────────────────────────────────────\n",
    "# Exact columns expected if you drop in the real CSV\n",
    "WAGENINGEN_COLS = [\n",
    "    'cow_id',            # integer cow identifier\n",
    "    'date',              # YYYY-MM-DD\n",
    "    'pen_id',            # pen / group assignment\n",
    "    # Wageningen SensOor ear-tag signals (daily aggregates of hourly readings)\n",
    "    'activity',          # cumulative activity count (arbitrary units)\n",
    "    'highly_active',     # hours/day classified as highly active\n",
    "    'rumination_min',    # total daily rumination time (minutes)\n",
    "    'feeding_min',       # total daily feeding activity (minutes)\n",
    "    'ear_temp_c',        # mean daily ear temperature (°C)\n",
    "    # Farm management records (Tier 1 — every farm has these)\n",
    "    'milk_yield_kg',     # daily milk yield\n",
    "    'health_event',      # 1 = vet treatment recorded that day\n",
    "    'feeding_visits',    # feeding station visit count\n",
    "    'days_in_milk',      # DIM since last calving\n",
    "    'bunk_id',           # feeding bunk ID (for edge construction)\n",
    "]\n",
    "\n",
    "SENSOR_FEATURES = [\n",
    "    'activity', 'highly_active', 'rumination_min', 'feeding_min', 'ear_temp_c',\n",
    "    'milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk',\n",
    "]\n",
    "N_FEATURES  = len(SENSOR_FEATURES)\n",
    "WINDOW_DAYS = 7     # 7-day rolling history per node\n",
    "DISEASES    = ['mastitis', 'brd', 'lameness']\n",
    "\n",
    "print(f'Feature vector: {N_FEATURES} signals × {WINDOW_DAYS} days = '\n",
    "      f'{N_FEATURES * WINDOW_DAYS} input dims per cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Synthetic farm generator matching Wageningen sensor profile ──────────\n",
    "# Means and SDs from Table 2, Rutten et al. 2017\n",
    "N_COWS  = 60\n",
    "N_PENS  = 6\n",
    "N_BUNKS = 4\n",
    "N_DAYS  = 90\n",
    "START   = datetime(2025, 10, 1)\n",
    "\n",
    "def generate_farm(n_cows=N_COWS, n_pens=N_PENS, n_bunks=N_BUNKS,\n",
    "                  n_days=N_DAYS, seed=42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pen_assign  = {i: i // (n_cows // n_pens) for i in range(n_cows)}\n",
    "    bunk_pref   = {i: rng.integers(0, n_bunks) for i in range(n_cows)}\n",
    "    dim_base    = {i: int(rng.integers(5, 300)) for i in range(n_cows)}\n",
    "    base_yield  = {i: float(rng.normal(28, 4).clip(18, 45)) for i in range(n_cows)}\n",
    "\n",
    "    rows = []\n",
    "    for day in range(n_days):\n",
    "        date = START + timedelta(days=day)\n",
    "        for cow in range(n_cows):\n",
    "            # Ear-tag signals (Wageningen profile)\n",
    "            activity      = float(rng.normal(450, 80).clip(200, 800))\n",
    "            highly_active = float(rng.normal(2.5, 0.8).clip(0, 8))\n",
    "            rumination    = float(rng.normal(480, 45).clip(300, 620))\n",
    "            feeding       = float(rng.normal(210, 35).clip(100, 360))\n",
    "            ear_temp      = float(rng.normal(38.5, 0.3).clip(37.0, 40.5))\n",
    "            # Farm management\n",
    "            milk          = float(rng.normal(base_yield[cow], 1.5).clip(10, 50))\n",
    "            health        = int(rng.random() < 0.01)\n",
    "            visits        = int(rng.integers(3, 10))\n",
    "            dim           = dim_base[cow] + day\n",
    "            bunk          = bunk_pref[cow] if rng.random() > 0.2 else rng.integers(0, n_bunks)\n",
    "\n",
    "            rows.append(dict(\n",
    "                cow_id=cow, date=date,\n",
    "                pen_id=pen_assign[cow], bunk_id=int(bunk),\n",
    "                activity=activity, highly_active=highly_active,\n",
    "                rumination_min=rumination, feeding_min=feeding, ear_temp_c=ear_temp,\n",
    "                milk_yield_kg=milk, health_event=health,\n",
    "                feeding_visits=visits, days_in_milk=dim,\n",
    "            ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ─── Data loading: real or synthetic ────────────────────────────────────\n",
    "USE_REAL_DATA = Path('data/wageningen.csv').exists()\n",
    "\n",
    "if USE_REAL_DATA:\n",
    "    FARM_DF = pd.read_csv('data/wageningen.csv', parse_dates=['date'])\n",
    "    print(f'Loaded real Wageningen data: {FARM_DF.shape}')\n",
    "else:\n",
    "    FARM_DF = generate_farm()\n",
    "    FARM_DF.to_csv(DATA_DIR / 'farm_synthetic.csv', index=False)\n",
    "    print(f'Using synthetic data: {FARM_DF.shape[0]:,} rows — '\n",
    "          'drop data/wageningen.csv + set USE_REAL_DATA=True to switch')\n",
    "\n",
    "FARM_DF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 02 · Dynamic Contact Graph\n",
    "\n",
    "Two edge types — both from records every farm already keeps:\n",
    "\n",
    "| Edge type | Condition | Weight |\n",
    "|-----------|-----------|--------|\n",
    "| Pen | Two cows in the same pen | 1.0 |\n",
    "| Bunk | Same feeding station visit | co-visit frequency (capped 3×) |\n",
    "\n",
    "Graph rebuilt every 24 h. Node features = **7-day rolling window**, zero-padded for any missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(farm_df: pd.DataFrame, snapshot_date,\n",
    "                window: int = WINDOW_DAYS) -> Data:\n",
    "    \"\"\"\n",
    "    Build a single PyG Data snapshot.\n",
    "\n",
    "    Returns Data with:\n",
    "      .x_seq      [N, T, F]  — sequence for GRU\n",
    "      .edge_index [2, E]\n",
    "      .edge_attr  [E, 1]     — edge weights\n",
    "      .cow_ids    list[int]\n",
    "      .date       str\n",
    "    \"\"\"\n",
    "    snap  = pd.Timestamp(snapshot_date)\n",
    "    start = snap - timedelta(days=window - 1)\n",
    "    win   = farm_df[(farm_df['date'] >= start) & (farm_df['date'] <= snap)].copy()\n",
    "\n",
    "    cows       = sorted(win['cow_id'].unique())\n",
    "    cow_to_idx = {c: i for i, c in enumerate(cows)}\n",
    "    N          = len(cows)\n",
    "\n",
    "    # ── Node features: rolling 7-day window ──────────────────────────────\n",
    "    dates = sorted(win['date'].unique())[-window:]\n",
    "    x_seq = np.zeros((N, window, N_FEATURES), dtype=np.float32)\n",
    "\n",
    "    for t, d in enumerate(dates):\n",
    "        day = win[win['date'] == d].set_index('cow_id')\n",
    "        for f_idx, feat in enumerate(SENSOR_FEATURES):\n",
    "            if feat in day.columns:\n",
    "                for cow, idx in cow_to_idx.items():\n",
    "                    if cow in day.index:\n",
    "                        x_seq[idx, t, f_idx] = day.loc[cow, feat]\n",
    "\n",
    "    # Per-feature standardisation (across cows × days)\n",
    "    for f in range(N_FEATURES):\n",
    "        v = x_seq[:, :, f]\n",
    "        x_seq[:, :, f] = (v - v.mean()) / (v.std() + 1e-8)\n",
    "\n",
    "    # ── Edges ─────────────────────────────────────────────────────────────\n",
    "    today = win[win['date'] == snap]\n",
    "\n",
    "    def make_clique_edges(groups: Dict[int, List[int]], weight_fn):\n",
    "        src, dst, w = [], [], []\n",
    "        for members in groups.values():\n",
    "            for i in members:\n",
    "                for j in members:\n",
    "                    if i != j:\n",
    "                        src.append(i); dst.append(j)\n",
    "                        w.append(weight_fn(len(members)))\n",
    "        return src, dst, w\n",
    "\n",
    "    pen_groups  = {}\n",
    "    bunk_groups = {}\n",
    "    for _, row in today.iterrows():\n",
    "        idx = cow_to_idx[row['cow_id']]\n",
    "        if 'pen_id'  in today.columns: pen_groups.setdefault(int(row['pen_id']),  []).append(idx)\n",
    "        if 'bunk_id' in today.columns: bunk_groups.setdefault(int(row['bunk_id']), []).append(idx)\n",
    "\n",
    "    ps, pd_, pw = make_clique_edges(pen_groups,  lambda n: 1.0)\n",
    "    bs, bd, bw  = make_clique_edges(bunk_groups, lambda n: min(n / 5.0, 3.0))\n",
    "\n",
    "    all_src = ps + bs\n",
    "    all_dst = pd_ + bd\n",
    "    all_w   = pw + bw\n",
    "\n",
    "    if all_src:\n",
    "        edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
    "        edge_attr  = torch.tensor(all_w, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr  = torch.zeros((0, 1), dtype=torch.float)\n",
    "\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data.x_seq     = torch.tensor(x_seq, dtype=torch.float)\n",
    "    data.num_nodes = N\n",
    "    data.cow_ids   = cows\n",
    "    data.date      = str(snap.date())\n",
    "    return data\n",
    "\n",
    "\n",
    "# Smoke test\n",
    "g = build_graph(FARM_DF, FARM_DF['date'].max())\n",
    "print(f'Graph: {g.num_nodes} nodes  {g.edge_index.shape[1]} edges')\n",
    "print(f'x_seq: {g.x_seq.shape}   (N, T, F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_contact_graph(graph: Data, title='Herd Contact Graph'):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(graph.num_nodes))\n",
    "    ei = graph.edge_index.t().numpy()\n",
    "    ea = graph.edge_attr.squeeze().numpy()\n",
    "    for k, (i, j) in enumerate(ei):\n",
    "        G.add_edge(int(i), int(j), weight=float(ea[k]) if k < len(ea) else 1.0)\n",
    "\n",
    "    pen_c = ['#2E5E1E','#C9983A','#5C3D1E','#6A9E48','#8C8070','#2C1A0E']\n",
    "    n     = graph.num_nodes\n",
    "    cols  = [pen_c[(c // (n // N_PENS)) % len(pen_c)] for c in range(n)]\n",
    "\n",
    "    pos = nx.spring_layout(G, seed=42, k=0.6)\n",
    "    fig, ax = plt.subplots(figsize=(12, 7))\n",
    "    ax.set_facecolor('#131008'); fig.patch.set_facecolor('#131008')\n",
    "\n",
    "    pen_e  = [(u,v) for u,v,d in G.edges(data=True) if abs(d['weight']-1.0)<0.01]\n",
    "    bunk_e = [(u,v) for u,v,d in G.edges(data=True) if abs(d['weight']-1.0)>0.01]\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=cols,  node_size=200, ax=ax, alpha=0.9)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=6, font_color='#F2EDE4', ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=pen_e,  edge_color='#6A9E48', alpha=0.35, width=0.8,  ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=bunk_e, edge_color='#C9983A', alpha=0.65, width=1.6,  ax=ax)\n",
    "\n",
    "    ax.legend(handles=[\n",
    "        mpatches.Patch(color='#6A9E48', label='Pen edge (w=1.0)'),\n",
    "        mpatches.Patch(color='#C9983A', label='Bunk co-visit edge'),\n",
    "    ], facecolor='#1E1A10', labelcolor='#F2EDE4', fontsize=9)\n",
    "    ax.set_title(title, color='#F2EDE4', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_contact_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 03 · Synthetic Disease Injection\n",
    "\n",
    "The Wageningen dataset has no labeled disease outbreaks — it was used for calving prediction.\n",
    "We generate supervised labels by injecting disease events and propagating contagion through\n",
    "the contact graph using transmission rates from published literature:\n",
    "\n",
    "| Disease | Daily transmission p per contact | Source |\n",
    "|---------|----------------------------------|--------|\n",
    "| Mastitis | 0.15 | Zadoks et al. 2011, J Dairy Sci |\n",
    "| BRD | 0.25 | Snowder et al. 2006, J Anim Sci |\n",
    "| Lameness | 0.05 | Fourichon et al. 2003, J Dairy Sci |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSMISSION = {'mastitis': 0.15, 'brd': 0.25, 'lameness': 0.05}\n",
    "BACKGROUND   = {'mastitis': 0.008, 'brd': 0.005, 'lameness': 0.006}\n",
    "\n",
    "\n",
    "def inject_disease(graph: Data, disease: str, n_seeds: int = 1,\n",
    "                   rng: Optional[np.random.Generator] = None) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Inject a single disease event and propagate for 2 rounds (= 48 h).\n",
    "    Returns binary label tensor [N] — sick at T+48h.\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    N   = graph.num_nodes\n",
    "    ei  = graph.edge_index.numpy()          # [2, E]\n",
    "    ew  = graph.edge_attr.squeeze().numpy() # [E]\n",
    "    p   = TRANSMISSION[disease]\n",
    "\n",
    "    labels = (rng.random(N) < BACKGROUND[disease]).astype(int)\n",
    "    if n_seeds > 0:\n",
    "        labels[rng.choice(N, size=min(n_seeds, N), replace=False)] = 1\n",
    "\n",
    "    for _ in range(2):                      # 2 rounds = T+48h\n",
    "        new = labels.copy()\n",
    "        for k in range(ei.shape[1]):\n",
    "            src, dst = ei[0, k], ei[1, k]\n",
    "            if labels[src] == 1 and new[dst] == 0:\n",
    "                if rng.random() < min(p * float(ew[k]), 1.0):\n",
    "                    new[dst] = 1\n",
    "        labels = new\n",
    "    return torch.tensor(labels, dtype=torch.float)\n",
    "\n",
    "\n",
    "def make_labels(graph: Data, rng=None) -> torch.Tensor:\n",
    "    \"\"\"[N, 3] label tensor — one column per disease.\"\"\"\n",
    "    if rng is None: rng = np.random.default_rng()\n",
    "    return torch.stack([\n",
    "        inject_disease(graph, d, n_seeds=int(rng.integers(0, 3)), rng=rng)\n",
    "        for d in DISEASES\n",
    "    ], dim=1)\n",
    "\n",
    "\n",
    "demo_y = make_labels(g, rng=np.random.default_rng(42))\n",
    "print('Label shape:', demo_y.shape)\n",
    "for i, d in enumerate(DISEASES):\n",
    "    pos = demo_y[:, i].sum().int().item()\n",
    "    print(f'  {d:10s}: {pos}/{g.num_nodes} positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Build the full labelled dataset ────────────────────────────────────\n",
    "# n_runs injection runs per snapshot date → ~580 labelled graphs (>500 target)\n",
    "\n",
    "def build_dataset(farm_df: pd.DataFrame, n_runs: int = 7,\n",
    "                  window: int = WINDOW_DAYS) -> List[Data]:\n",
    "    dates   = sorted(farm_df['date'].unique())[window:]\n",
    "    dataset = []\n",
    "    rng     = np.random.default_rng(42)\n",
    "    print(f'Building {len(dates)} × {n_runs} = {len(dates)*n_runs} labelled snapshots…')\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        base = build_graph(farm_df, date, window)\n",
    "        for _ in range(n_runs):\n",
    "            g = base.clone()\n",
    "            g.y = make_labels(g, rng)\n",
    "            dataset.append(g)\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f'  {i+1}/{len(dates)}')\n",
    "\n",
    "    print(f'Done — {len(dataset)} graphs')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "DATASET = build_dataset(FARM_DF)\n",
    "torch.save(DATASET, DATA_DIR / 'dataset.pt')\n",
    "print(f'Saved → data/dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 04 · TauronGNN — GraphSAGE + GRU\n",
    "\n",
    "```\n",
    "x_seq  [N, T=7, F=9]\n",
    "         │\n",
    "       GRU  hidden=128          temporal encoding of each cow's 7-day window\n",
    "         │\n",
    "       h  [N, 128]\n",
    "         │\n",
    "       SAGEConv  (128→128)      hop 1 — aggregate 1-hop neighbours\n",
    "       SAGEConv  (128→128)      hop 2 — aggregate 2-hop neighbours\n",
    "         │\n",
    "       Linear (128→3) + Sigmoid\n",
    "         │\n",
    "       risk  [N, 3]             mastitis | BRD | lameness  — T+48h\n",
    "```\n",
    "\n",
    "Same graph, same weights — disease specialisation lives in the three output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TauronGNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_features: int = N_FEATURES,\n",
    "                 window: int = WINDOW_DAYS,\n",
    "                 hidden: int = 128,\n",
    "                 n_diseases: int = 3,\n",
    "                 dropout: float = 0.3):\n",
    "        super().__init__()\n",
    "        # Temporal encoder\n",
    "        self.gru = nn.GRU(input_size=n_features, hidden_size=hidden,\n",
    "                          num_layers=1, batch_first=True)\n",
    "        # Graph encoder — 2 SAGE layers = 2-hop neighbourhood\n",
    "        self.sage1 = SAGEConv(hidden, hidden)\n",
    "        self.sage2 = SAGEConv(hidden, hidden)\n",
    "        self.norm1 = nn.LayerNorm(hidden)\n",
    "        self.norm2 = nn.LayerNorm(hidden)\n",
    "        self.drop  = nn.Dropout(dropout)\n",
    "        # Three-head decoder — one neuron per disease\n",
    "        self.decoder = nn.Linear(hidden, n_diseases)\n",
    "\n",
    "    def forward(self, data: Data) -> torch.Tensor:\n",
    "        # 1. Temporal: GRU over 7-day window → last hidden state\n",
    "        _, h_n = self.gru(data.x_seq)          # h_n: [1, N, H]\n",
    "        h = h_n.squeeze(0)                     # [N, H]\n",
    "\n",
    "        # 2. Graph: 2-hop message passing\n",
    "        h = self.drop(F.relu(self.norm1(self.sage1(h, data.edge_index))))\n",
    "        h = self.drop(F.relu(self.norm2(self.sage2(h, data.edge_index))))\n",
    "\n",
    "        # 3. Decode → three risk scores per cow\n",
    "        return torch.sigmoid(self.decoder(h))  # [N, 3]\n",
    "\n",
    "\n",
    "model = TauronGNN().to(DEVICE)\n",
    "sample = DATASET[0].to(DEVICE)\n",
    "with torch.no_grad():\n",
    "    out = model(sample)\n",
    "print(f'Output shape : {out.shape}   (expect [{sample.num_nodes}, 3])')\n",
    "print(f'Parameters   : {sum(p.numel() for p in model.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 05 · Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 80/20 train/val split on graph snapshots\n",
    "idx = list(range(len(DATASET)))\n",
    "train_idx, val_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "TRAIN = [DATASET[i] for i in train_idx]\n",
    "VAL   = [DATASET[i] for i in val_idx]\n",
    "print(f'Train: {len(TRAIN)}   Val: {len(VAL)}')\n",
    "\n",
    "# Positive-class weights to handle imbalance\n",
    "all_y      = torch.cat([g.y for g in DATASET])\n",
    "pos_frac   = all_y.mean(0).clamp(1e-4, 1-1e-4)\n",
    "pos_weight = ((1 - pos_frac) / pos_frac).to(DEVICE)\n",
    "criterion  = nn.BCELoss()\n",
    "\n",
    "\n",
    "def train_epoch(model, graphs, opt):\n",
    "    model.train()\n",
    "    total = 0.0\n",
    "    random.shuffle(graphs)\n",
    "    for g in graphs:\n",
    "        g = g.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        loss = criterion(model(g), g.y.to(DEVICE))\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step()\n",
    "        total += loss.item()\n",
    "    return total / len(graphs)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, graphs):\n",
    "    model.eval()\n",
    "    preds, trues, loss_sum = [], [], 0.0\n",
    "    for g in graphs:\n",
    "        g = g.to(DEVICE)\n",
    "        p = model(g)\n",
    "        loss_sum += criterion(p, g.y.to(DEVICE)).item()\n",
    "        preds.append(p.cpu()); trues.append(g.y.cpu())\n",
    "\n",
    "    P = torch.cat(preds).numpy()\n",
    "    T = torch.cat(trues).numpy()\n",
    "    aurocs = {}\n",
    "    for i, d in enumerate(DISEASES):\n",
    "        yt, yp = T[:, i], P[:, i]\n",
    "        aurocs[d] = roc_auc_score(yt, yp) if yt.sum() > 0 and (1-yt).sum() > 0 else float('nan')\n",
    "    return loss_sum / len(graphs), aurocs, P, T\n",
    "\n",
    "\n",
    "print('Training helpers ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "model    = TauronGNN().to(DEVICE)\n",
    "opt      = Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "sched    = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=N_EPOCHS)\n",
    "\n",
    "history    = {'train_loss': [], 'val_loss': [], 'auroc': {d: [] for d in DISEASES}}\n",
    "best_auroc = -1\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    tl = train_epoch(model, TRAIN, opt)\n",
    "    vl, aurocs, _, _ = evaluate(model, VAL)\n",
    "    sched.step()\n",
    "\n",
    "    history['train_loss'].append(tl)\n",
    "    history['val_loss'].append(vl)\n",
    "    mean_a = np.nanmean(list(aurocs.values()))\n",
    "    for d in DISEASES: history['auroc'][d].append(aurocs[d])\n",
    "\n",
    "    if mean_a > best_auroc:\n",
    "        best_auroc = mean_a\n",
    "        torch.save(model.state_dict(), MODEL_DIR / 'tauron_model.pt')\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        astr = '  '.join(f'{d[:3].upper()} {aurocs[d]:.3f}' for d in DISEASES)\n",
    "        print(f'ep {epoch:3d}  train {tl:.4f}  val {vl:.4f}  [{astr}]')\n",
    "\n",
    "print(f'\\nBest mean AUROC: {best_auroc:.4f}')\n",
    "print(f'Checkpoint → models/tauron_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 4), facecolor='#131008')\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_facecolor('#1E1A10')\n",
    "    [s.set_edgecolor('#3a3020') for s in ax.spines.values()]\n",
    "    ax.tick_params(colors='#8C8070')\n",
    "\n",
    "eps = range(1, N_EPOCHS + 1)\n",
    "ax1.plot(eps, history['train_loss'], color='#6A9E48', lw=1.5, label='Train')\n",
    "ax1.plot(eps, history['val_loss'],   color='#C9983A', lw=1.5, ls='--', label='Val')\n",
    "ax1.set_title('BCE Loss', color='#F2EDE4')\n",
    "ax1.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "dc = {'mastitis': '#6A9E48', 'brd': '#C9983A', 'lameness': '#8C8070'}\n",
    "for d in DISEASES:\n",
    "    ax2.plot(eps, history['auroc'][d], color=dc[d], lw=1.5, label=d.title())\n",
    "ax2.axhline(0.5, color='#3a3020', ls=':', lw=0.8)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_title('AUROC per Disease', color='#F2EDE4')\n",
    "ax2.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR / 'training_curves.png', dpi=150, bbox_inches='tight', facecolor='#131008')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 06 · Evaluation & Tier Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_DIR / 'tauron_model.pt', map_location=DEVICE))\n",
    "_, final_aurocs, val_preds, val_trues = evaluate(model, VAL)\n",
    "\n",
    "print('Final Validation AUROC')\n",
    "for d in DISEASES:\n",
    "    ap = average_precision_score(val_trues[:, DISEASES.index(d)],\n",
    "                                 val_preds[:, DISEASES.index(d)])\n",
    "    print(f'  {d:10s}  AUROC {final_aurocs[d]:.4f}  AP {ap:.4f}')\n",
    "print(f'  Mean AUROC: {np.nanmean(list(final_aurocs.values())):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4), facecolor='#131008')\n",
    "for i, (d, ax) in enumerate(zip(DISEASES, axes)):\n",
    "    ax.set_facecolor('#1E1A10')\n",
    "    [s.set_edgecolor('#3a3020') for s in ax.spines.values()]\n",
    "    ax.tick_params(colors='#8C8070')\n",
    "    yt, yp = val_trues[:, i], val_preds[:, i]\n",
    "    if yt.sum() > 0:\n",
    "        fpr, tpr, _ = roc_curve(yt, yp)\n",
    "        ax.plot(fpr, tpr, color=list(dc.values())[i], lw=2,\n",
    "                label=f'AUC {final_aurocs[d]:.3f}')\n",
    "    ax.plot([0,1],[0,1], color='#3a3020', ls=':', lw=0.8)\n",
    "    ax.set_title(d.title(), color='#F2EDE4')\n",
    "    ax.set_xlabel('FPR', color='#8C8070')\n",
    "    ax.set_ylabel('TPR', color='#8C8070')\n",
    "    ax.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "plt.suptitle('ROC Curves — TauronGNN', color='#F2EDE4')\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR / 'roc_curves.png', dpi=150, bbox_inches='tight', facecolor='#131008')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Risk score calibration across data tiers ─────────────────────────────\n",
    "# Simulate lower tiers by zeroing features unavailable without wearables/AMS\n",
    "\n",
    "TIER_FEATURES = {\n",
    "    1: ['milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk'],\n",
    "    2: ['milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk',\n",
    "        'feeding_min'],\n",
    "    3: SENSOR_FEATURES,   # all features including Wageningen ear-tag signals\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_tier(model, graphs, tier):\n",
    "    allowed = TIER_FEATURES[tier]\n",
    "    keep    = [SENSOR_FEATURES.index(f) for f in allowed if f in SENSOR_FEATURES]\n",
    "    mask    = torch.zeros(N_FEATURES)\n",
    "    mask[keep] = 1.0\n",
    "\n",
    "    tiered = []\n",
    "    for g in graphs:\n",
    "        g2 = g.clone()\n",
    "        g2.x_seq = g.x_seq * mask\n",
    "        tiered.append(g2)\n",
    "    _, aurocs, _, _ = evaluate(model, tiered)\n",
    "    return aurocs\n",
    "\n",
    "\n",
    "tier_aurocs = {t: eval_tier(model, VAL[:40], t) for t in [1, 2, 3]}\n",
    "\n",
    "print(f'{\"\":8s}  {\"mastitis\":>10}  {\"brd\":>8}  {\"lameness\":>10}  {\"mean\":>6}')\n",
    "for t in [1, 2, 3]:\n",
    "    r = tier_aurocs[t]\n",
    "    m = np.nanmean(list(r.values()))\n",
    "    print(f'Tier {t}    {r[\"mastitis\"]:>10.3f}  {r[\"brd\"]:>8.3f}  {r[\"lameness\"]:>10.3f}  {m:>6.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 07 · Inference + XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def predict(graph: Data) -> Dict:\n",
    "    \"\"\"cow_id → {mastitis, brd, lameness} risk scores.\"\"\"\n",
    "    model.eval()\n",
    "    risk = model(graph.to(DEVICE)).cpu()\n",
    "    return {\n",
    "        cid: {d: round(float(risk[i, j]), 3) for j, d in enumerate(DISEASES)}\n",
    "        for i, cid in enumerate(graph.cow_ids)\n",
    "    }\n",
    "\n",
    "\n",
    "def explain_cow(graph: Data, cow_idx: int) -> Dict:\n",
    "    \"\"\"\n",
    "    Gradient-based feature importance + highest-weight contact edge.\n",
    "    Returns structured JSON ready for the Claude API alert prompt.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    g = graph.clone().to(DEVICE)\n",
    "    g.x_seq.requires_grad_(True)\n",
    "\n",
    "    risk = model(g)[cow_idx]                      # [3]\n",
    "    dom  = risk.argmax().item()\n",
    "    risk[dom].backward()\n",
    "\n",
    "    # Feature importance: mean |gradient| over time dimension\n",
    "    grad     = g.x_seq.grad[cow_idx].abs().mean(0).cpu().numpy()  # [F]\n",
    "    top_f    = int(grad.argmax())\n",
    "    top_feat = SENSOR_FEATURES[top_f]\n",
    "\n",
    "    # Top contact edge for this cow\n",
    "    ei = graph.edge_index.numpy()\n",
    "    ea = graph.edge_attr.squeeze().numpy()\n",
    "    connected = [(k, int(ei[1, k])) for k in range(ei.shape[1]) if ei[0, k] == cow_idx]\n",
    "    top_edge  = None\n",
    "    if connected:\n",
    "        k, nbr = max(connected, key=lambda x: float(ea[x[0]]) if x[0] < len(ea) else 0)\n",
    "        top_edge = {'neighbour_cow': graph.cow_ids[nbr],\n",
    "                    'edge_weight':   round(float(ea[k]), 2)}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        all_risk = model(graph.to(DEVICE))[cow_idx].cpu()\n",
    "\n",
    "    return {\n",
    "        'cow_id':           f'#{graph.cow_ids[cow_idx]}',\n",
    "        'date':             graph.date,\n",
    "        'risk':             round(float(all_risk[dom]), 3),\n",
    "        'dominant_disease': DISEASES[dom],\n",
    "        'all_risks':        {d: round(float(all_risk[i]), 3) for i, d in enumerate(DISEASES)},\n",
    "        'top_feature':      top_feat,\n",
    "        'top_edge':         top_edge,\n",
    "    }\n",
    "\n",
    "\n",
    "# Demo on latest snapshot\n",
    "latest = build_graph(FARM_DF, FARM_DF['date'].max())\n",
    "scores = predict(latest)\n",
    "ranked = sorted(scores.items(), key=lambda x: max(x[1].values()), reverse=True)\n",
    "\n",
    "print('Top 5 at-risk cows:')\n",
    "for cid, r in ranked[:5]:\n",
    "    best = max(r, key=r.get)\n",
    "    print(f'  Cow #{cid:2d}  {best:10s}  {r[best]:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XAI output for top cow\n",
    "top_id  = ranked[0][0]\n",
    "top_idx = latest.cow_ids.index(top_id)\n",
    "xai     = explain_cow(latest, top_idx)\n",
    "print(json.dumps(xai, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 08 · Demo — Staged Event: Cow #47, Mastitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_demo(farm_df: pd.DataFrame, patient_zero: int = 47,\n",
    "               event_date: str = '2026-01-13') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inject a realistic 3-day prodromal signal for Cow #patient_zero\n",
    "    matching known mastitis sensor patterns from the Wageningen paper:\n",
    "    - activity drops before clinical onset\n",
    "    - ear temperature rises ~24h prior\n",
    "    - milk yield falls sharply on event day\n",
    "    \"\"\"\n",
    "    df   = farm_df.copy()\n",
    "    evd  = pd.Timestamp(event_date)\n",
    "\n",
    "    prodromes = [\n",
    "        (3, dict(activity=0.95, rumination_min=0.97, ear_temp_c=lambda x: x+0.2)),\n",
    "        (2, dict(activity=0.88, rumination_min=0.92, ear_temp_c=lambda x: x+0.5,\n",
    "                 milk_yield_kg=0.94)),\n",
    "        (1, dict(activity=0.78, rumination_min=0.85, ear_temp_c=lambda x: x+0.9,\n",
    "                 milk_yield_kg=0.88)),\n",
    "    ]\n",
    "    for delta, changes in prodromes:\n",
    "        mask = (df['cow_id'] == patient_zero) & (df['date'] == evd - timedelta(days=delta))\n",
    "        for col, fn in changes.items():\n",
    "            if mask.any() and col in df.columns:\n",
    "                df.loc[mask, col] = df.loc[mask, col].apply(\n",
    "                    fn if callable(fn) else lambda x, f=fn: x * f\n",
    "                )\n",
    "\n",
    "    # Event day — acute mastitis profile\n",
    "    mask = (df['cow_id'] == patient_zero) & (df['date'] == evd)\n",
    "    if mask.any():\n",
    "        df.loc[mask, 'milk_yield_kg']  *= 0.78\n",
    "        df.loc[mask, 'ear_temp_c']      = 39.8\n",
    "        df.loc[mask, 'activity']        *= 0.65\n",
    "        df.loc[mask, 'rumination_min'] *= 0.70\n",
    "        df.loc[mask, 'health_event']    = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extend to demo date and inject\n",
    "extra = pd.date_range('2025-12-30', '2026-01-15')\n",
    "rows  = []\n",
    "for d in extra:\n",
    "    for cow in range(N_COWS):\n",
    "        r = FARM_DF[FARM_DF['cow_id'] == cow].iloc[-1].copy()\n",
    "        r['date'] = d\n",
    "        r['milk_yield_kg'] += np.random.normal(0, 0.4)\n",
    "        rows.append(r)\n",
    "\n",
    "DEMO_DF    = pd.concat([FARM_DF, pd.DataFrame(rows)], ignore_index=True)\n",
    "DEMO_DF    = stage_demo(DEMO_DF)\n",
    "demo_graph = build_graph(DEMO_DF, '2026-01-13')\n",
    "demo_scores = predict(demo_graph)\n",
    "\n",
    "print('Cow #47 risks on 2026-01-13:')\n",
    "print(json.dumps(demo_scores[47], indent=2))\n",
    "\n",
    "xai47 = explain_cow(demo_graph, demo_graph.cow_ids.index(47))\n",
    "print('\\nXAI:')\n",
    "print(json.dumps(xai47, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk herd map — Cow #47 highlighted, transmission edges glowing\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "def plot_risk_map(graph, scores, highlight=47, title='Herd Risk Map'):\n",
    "    G    = nx.Graph()\n",
    "    G.add_nodes_from(graph.cow_ids)\n",
    "    ei   = graph.edge_index.t().numpy()\n",
    "    ea   = graph.edge_attr.squeeze().numpy()\n",
    "    i2id = {i: c for i, c in enumerate(graph.cow_ids)}\n",
    "    for k, (i, j) in enumerate(ei):\n",
    "        G.add_edge(i2id[i], i2id[j], weight=float(ea[k]) if k < len(ea) else 1.0)\n",
    "\n",
    "    cmap = LinearSegmentedColormap.from_list('risk', ['#2E5E1E','#C9983A','#8B0000'])\n",
    "    risk = {cid: max(r.values()) for cid, r in scores.items()}\n",
    "    cols  = [cmap(risk.get(c, 0)) for c in G.nodes]\n",
    "    sizes = [700 if c == highlight else 140 for c in G.nodes]\n",
    "\n",
    "    pos  = nx.spring_layout(G, seed=42, k=0.55)\n",
    "    fig, ax = plt.subplots(figsize=(13, 8))\n",
    "    ax.set_facecolor('#131008'); fig.patch.set_facecolor('#131008')\n",
    "\n",
    "    nbrs  = list(G.neighbors(highlight))\n",
    "    norm_e = [(u,v) for u,v in G.edges if highlight not in (u,v)]\n",
    "    glow_e = [(highlight, v) for v in nbrs]\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=norm_e, edge_color='#2a2015', width=0.6, ax=ax)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=glow_e, edge_color='#C9983A', width=2.2, alpha=0.85, ax=ax)\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=cols, node_size=sizes, ax=ax, alpha=0.92)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=5, font_color='#F2EDE4', ax=ax)\n",
    "\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0, 1))\n",
    "    sm.set_array([])\n",
    "    cb = plt.colorbar(sm, ax=ax, fraction=0.024, pad=0.02)\n",
    "    cb.set_label('Max Risk Score', color='#8C8070')\n",
    "    cb.ax.yaxis.set_tick_params(color='#8C8070')\n",
    "    plt.setp(cb.ax.yaxis.get_ticklabels(), color='#8C8070')\n",
    "\n",
    "    ax.set_title(title, color='#F2EDE4', fontsize=12)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DATA_DIR / 'demo_risk_graph.png', dpi=150,\n",
    "                bbox_inches='tight', facecolor='#131008')\n",
    "    plt.show()\n",
    "\n",
    "plot_risk_map(demo_graph, demo_scores,\n",
    "              title='Herd Risk Map · 2026-01-13 · Cow #47 Mastitis Event')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 09 · FastAPI Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_CODE = '''\n",
    "# api.py — run with: uvicorn api:app --reload\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import torch, pandas as pd\n",
    "from fastapi import FastAPI, UploadFile, HTTPException\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import anthropic\n",
    "\n",
    "app = FastAPI(title=\"Tauron\", version=\"1.0\")\n",
    "app.add_middleware(CORSMiddleware, allow_origins=[\"*\"],\n",
    "                   allow_methods=[\"*\"], allow_headers=[\"*\"])\n",
    "\n",
    "_model = _graph = _scores = None\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "def load():\n",
    "    global _model, _graph, _scores\n",
    "    # Import pipeline helpers from notebook-exported module here\n",
    "    print(\"Tauron API ready\")\n",
    "\n",
    "\n",
    "@app.get(\"/herd\")\n",
    "def herd():\n",
    "    if _scores is None: raise HTTPException(503, \"model not loaded\")\n",
    "    ei = _graph.edge_index.t().tolist()\n",
    "    ew = _graph.edge_attr.squeeze().tolist()\n",
    "    return {\"cows\": _scores,\n",
    "            \"edges\": [{\"src\": e[0], \"dst\": e[1], \"w\": w} for e, w in zip(ei, ew)]}\n",
    "\n",
    "\n",
    "@app.get(\"/alert/{cow_id}\")\n",
    "def alert(cow_id: int):\n",
    "    if _graph is None: raise HTTPException(503, \"model not loaded\")\n",
    "    if cow_id not in _graph.cow_ids: raise HTTPException(404, f\"cow {cow_id} not found\")\n",
    "    return explain_cow(_graph, _graph.cow_ids.index(cow_id))\n",
    "\n",
    "\n",
    "@app.get(\"/explain/{cow_id}\")\n",
    "def explain(cow_id: int):\n",
    "    if _graph is None: raise HTTPException(503, \"model not loaded\")\n",
    "    if cow_id not in _graph.cow_ids: raise HTTPException(404, f\"cow {cow_id} not found\")\n",
    "    xai = explain_cow(_graph, _graph.cow_ids.index(cow_id))\n",
    "    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n",
    "    msg = client.messages.create(\n",
    "        model=\"claude-sonnet-4-6\", max_tokens=120,\n",
    "        messages=[{\"role\": \"user\", \"content\":\n",
    "            f\"You are a dairy herd advisor. Write one plain-English action sentence \"\n",
    "            f\"a farmer can act on immediately based on this model output: {json.dumps(xai)}\"}]\n",
    "    )\n",
    "    return {\"cow_id\": f\"#{cow_id}\", \"alert\": msg.content[0].text, \"xai\": xai}\n",
    "\n",
    "\n",
    "@app.post(\"/api/ingest\")\n",
    "async def ingest(file: Optional[UploadFile] = None, tier: int = 1):\n",
    "    if file is None: raise HTTPException(400, \"provide a CSV file\")\n",
    "    import io\n",
    "    df = pd.read_csv(io.StringIO((await file.read()).decode()))\n",
    "    return {\"status\": \"ok\", \"rows\": len(df), \"tier\": tier}\n",
    "'''\n",
    "\n",
    "Path('api.py').write_text(API_CODE.strip())\n",
    "print('api.py written.')\n",
    "print('Start with: source venv/bin/activate && uvicorn api:app --reload')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | Output |\n",
    "|-----------|--------|\n",
    "| Wageningen-profile farm data | `data/farm_synthetic.csv` (swap for `data/wageningen.csv`) |\n",
    "| Contact graph builder | `build_graph(farm_df, date)` → PyG `Data` |\n",
    "| Synthetic disease labels | `inject_disease()` + `make_labels()` → 500+ snapshots → `data/dataset.pt` |\n",
    "| TauronGNN (GraphSAGE + GRU) | 128-dim hidden, 2-hop, 3-head decoder |\n",
    "| Training (50 epochs, BCE) | `models/tauron_model.pt` (best AUROC checkpoint) |\n",
    "| Evaluation | ROC + AUROC per disease, tier calibration table |\n",
    "| Inference + XAI | `predict()` + `explain_cow()` → structured JSON |\n",
    "| Demo event | Cow #47 mastitis, 2026-01-13, transmission glow |\n",
    "| FastAPI backend | `api.py` — `/herd`, `/alert/{id}`, `/explain/{id}`, `/api/ingest` |\n",
    "\n",
    "**To swap in the real Wageningen data:**\n",
    "1. Request data from C.J. Rutten via https://research.wur.nl/en/publications/sensor-data-on-cow-activity-rumination-and-ear-temperature-improv/\n",
    "2. Save as `data/wageningen.csv` with columns matching `WAGENINGEN_COLS`\n",
    "3. Re-run from Section 01 — `USE_REAL_DATA` flips automatically"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tauron ML",
   "language": "python",
   "name": "tauron"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
