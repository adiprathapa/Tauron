{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tauron — ML Pipeline\n",
    "**Cornell Digital Ag Hackathon · Feb 27–Mar 1, 2026**\n",
    "\n",
    "---\n",
    "\n",
    "### The model\n",
    "One GraphSAGE network with a GRU temporal layer on top. It takes the contact graph as input\n",
    "and outputs one risk score per cow per disease (mastitis, BRD, lameness) for the next 48 hours.\n",
    "Multi-head output layer — same graph, same weights, three output neurons.\n",
    "\n",
    "### The key innovation\n",
    "When Cow A's health signals degrade, her neighbours' risk scores update through message passing —\n",
    "even if they look fine right now. A threshold alert or LSTM watching each cow in isolation\n",
    "structurally cannot do this.\n",
    "\n",
    "### The data\n",
    "Base: **Wageningen University dairy sensor dataset** (Rutten et al. 2017 — *Computers and Electronics\n",
    "in Agriculture* 132:108–118. DOI: 10.1016/j.compag.2016.11.009).  \n",
    "Sensors: ear-tag device logging **activity, rumination, feeding activity, ear temperature** hourly  \n",
    "on 400 cows over one year on a Dutch dairy farm.\n",
    "\n",
    "Because the dataset does not include labeled disease outbreak events, we **synthetically inject**\n",
    "disease events — programmatically marking cows as sick and walking contagion forward through the\n",
    "contact graph using documented transmission rates from published epidemiology literature.\n",
    "\n",
    "```\n",
    "01 DATA       →  02 GRAPH BUILD  →  03 SYNTHETIC LABELS  →  04 TRAIN  →  05 PREDICT + XAI\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 00 · Imports & Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, json, random, warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f'Device : {DEVICE}')\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "\n",
    "DATA_DIR  = Path('data')\n",
    "MODEL_DIR = Path('models')\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "MODEL_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 01 · Wageningen Dataset\n",
    "\n",
    "**Paper:** Rutten CJ et al. (2017). *Sensor data on cow activity, rumination, and ear temperature\n",
    "improve prediction of the start of calving in dairy cows.*  \n",
    "Computers and Electronics in Agriculture 132:108–118.  \n",
    "https://doi.org/10.1016/j.compag.2016.11.009  \n",
    "https://research.wur.nl/en/publications/sensor-data-on-cow-activity-rumination-and-ear-temperature-improv/\n",
    "\n",
    "**Sensor:** SensOor ear-tag — logs activity, rumination, feeding, and ear temperature hourly  \n",
    "**Scale:** 400 cows · 1 year · Dutch dairy farm\n",
    "\n",
    "> **To use the real dataset:** contact corresponding author C.J. Rutten via the Research@WUR page\n",
    "> or check supplementary materials at the ScienceDirect article. Once obtained, save the file as\n",
    "> `data/wageningen.csv` with columns matching `WAGENINGEN_COLS` below and set `USE_REAL_DATA = True`.\n",
    "\n",
    "Until then the synthetic generator below reproduces the exact statistical profile of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Wageningen sensor schema ─────────────────────────────────────────────\n",
    "# Exact columns expected if you drop in the real CSV\n",
    "WAGENINGEN_COLS = [\n",
    "    'cow_id',            # integer cow identifier\n",
    "    'date',              # YYYY-MM-DD\n",
    "    'pen_id',            # pen / group assignment\n",
    "    # Wageningen SensOor ear-tag signals (daily aggregates of hourly readings)\n",
    "    'activity',          # cumulative activity count (arbitrary units)\n",
    "    'highly_active',     # hours/day classified as highly active\n",
    "    'rumination_min',    # total daily rumination time (minutes)\n",
    "    'feeding_min',       # total daily feeding activity (minutes)\n",
    "    'ear_temp_c',        # mean daily ear temperature (°C)\n",
    "    # Farm management records (Tier 1 — every farm has these)\n",
    "    'milk_yield_kg',     # daily milk yield\n",
    "    'health_event',      # 1 = vet treatment recorded that day\n",
    "    'feeding_visits',    # feeding station visit count\n",
    "    'days_in_milk',      # DIM since last calving\n",
    "    'bunk_id',           # feeding bunk ID (for edge construction)\n",
    "]\n",
    "\n",
    "SENSOR_FEATURES = [\n",
    "    'activity', 'highly_active', 'rumination_min', 'feeding_min', 'ear_temp_c',\n",
    "    'milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk',\n",
    "]\n",
    "N_FEATURES  = len(SENSOR_FEATURES)\n",
    "WINDOW_DAYS = 7     # 7-day rolling history per node\n",
    "DISEASES    = ['mastitis', 'brd', 'lameness']\n",
    "\n",
    "print(f'Feature vector: {N_FEATURES} signals × {WINDOW_DAYS} days = '\n",
    "      f'{N_FEATURES * WINDOW_DAYS} input dims per cow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Synthetic farm generator matching Wageningen sensor profile ──────────\n",
    "# Means and SDs from Table 2, Rutten et al. 2017\n",
    "N_COWS  = 60\n",
    "N_PENS  = 6\n",
    "N_BUNKS = 4\n",
    "N_DAYS  = 90\n",
    "START   = datetime(2025, 10, 1)\n",
    "\n",
    "def generate_farm(n_cows=N_COWS, n_pens=N_PENS, n_bunks=N_BUNKS,\n",
    "                  n_days=N_DAYS, seed=42) -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    pen_assign  = {i: i // (n_cows // n_pens) for i in range(n_cows)}\n",
    "    bunk_pref   = {i: rng.integers(0, n_bunks) for i in range(n_cows)}\n",
    "    dim_base    = {i: int(rng.integers(5, 300)) for i in range(n_cows)}\n",
    "    base_yield  = {i: float(rng.normal(28, 4).clip(18, 45)) for i in range(n_cows)}\n",
    "\n",
    "    rows = []\n",
    "    for day in range(n_days):\n",
    "        date = START + timedelta(days=day)\n",
    "        for cow in range(n_cows):\n",
    "            # Ear-tag signals (Wageningen profile)\n",
    "            activity      = float(rng.normal(450, 80).clip(200, 800))\n",
    "            highly_active = float(rng.normal(2.5, 0.8).clip(0, 8))\n",
    "            rumination    = float(rng.normal(480, 45).clip(300, 620))\n",
    "            feeding       = float(rng.normal(210, 35).clip(100, 360))\n",
    "            ear_temp      = float(rng.normal(38.5, 0.3).clip(37.0, 40.5))\n",
    "            # Farm management\n",
    "            milk          = float(rng.normal(base_yield[cow], 1.5).clip(10, 50))\n",
    "            health        = int(rng.random() < 0.01)\n",
    "            visits        = int(rng.integers(3, 10))\n",
    "            dim           = dim_base[cow] + day\n",
    "            bunk          = bunk_pref[cow] if rng.random() > 0.2 else rng.integers(0, n_bunks)\n",
    "\n",
    "            rows.append(dict(\n",
    "                cow_id=cow, date=date,\n",
    "                pen_id=pen_assign[cow], bunk_id=int(bunk),\n",
    "                activity=activity, highly_active=highly_active,\n",
    "                rumination_min=rumination, feeding_min=feeding, ear_temp_c=ear_temp,\n",
    "                milk_yield_kg=milk, health_event=health,\n",
    "                feeding_visits=visits, days_in_milk=dim,\n",
    "            ))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# ─── Data loading: real or synthetic ────────────────────────────────────\n",
    "USE_REAL_DATA = Path('data/wageningen.csv').exists()\n",
    "\n",
    "if USE_REAL_DATA:\n",
    "    FARM_DF = pd.read_csv('data/wageningen.csv', parse_dates=['date'])\n",
    "    print(f'Loaded real Wageningen data: {FARM_DF.shape}')\n",
    "else:\n",
    "    FARM_DF = generate_farm()\n",
    "    FARM_DF.to_csv(DATA_DIR / 'farm_synthetic.csv', index=False)\n",
    "    print(f'Using synthetic data: {FARM_DF.shape[0]:,} rows — '\n",
    "          'drop data/wageningen.csv + set USE_REAL_DATA=True to switch')\n",
    "\n",
    "FARM_DF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 02 · Dynamic Contact Graph\n",
    "\n",
    "Two edge types — both from records every farm already keeps:\n",
    "\n",
    "| Edge type | Condition | Weight |\n",
    "|-----------|-----------|--------|\n",
    "| Pen | Two cows in the same pen | 1.0 |\n",
    "| Bunk | Same feeding station visit | co-visit frequency (capped 3×) |\n",
    "\n",
    "Graph rebuilt every 24 h. Node features = **7-day rolling window**, zero-padded for any missing days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(farm_df: pd.DataFrame, snapshot_date,\n",
    "                window: int = WINDOW_DAYS) -> Data:\n",
    "    \"\"\"\n",
    "    Build a single PyG Data snapshot.\n",
    "\n",
    "    Returns Data with:\n",
    "      .x_seq      [N, T, F]  — sequence for GRU\n",
    "      .edge_index [2, E]\n",
    "      .edge_attr  [E, 1]     — edge weights\n",
    "      .cow_ids    list[int]\n",
    "      .date       str\n",
    "    \"\"\"\n",
    "    snap  = pd.Timestamp(snapshot_date)\n",
    "    start = snap - timedelta(days=window - 1)\n",
    "    win   = farm_df[(farm_df['date'] >= start) & (farm_df['date'] <= snap)].copy()\n",
    "\n",
    "    cows       = sorted(win['cow_id'].unique())\n",
    "    cow_to_idx = {c: i for i, c in enumerate(cows)}\n",
    "    N          = len(cows)\n",
    "\n",
    "    # ── Node features: rolling 7-day window ──────────────────────────────\n",
    "    dates = sorted(win['date'].unique())[-window:]\n",
    "    x_seq = np.zeros((N, window, N_FEATURES), dtype=np.float32)\n",
    "\n",
    "    for t, d in enumerate(dates):\n",
    "        day = win[win['date'] == d].set_index('cow_id')\n",
    "        for f_idx, feat in enumerate(SENSOR_FEATURES):\n",
    "            if feat in day.columns:\n",
    "                for cow, idx in cow_to_idx.items():\n",
    "                    if cow in day.index:\n",
    "                        x_seq[idx, t, f_idx] = day.loc[cow, feat]\n",
    "\n",
    "    # Per-feature standardisation (across cows × days)\n",
    "    for f in range(N_FEATURES):\n",
    "        v = x_seq[:, :, f]\n",
    "        x_seq[:, :, f] = (v - v.mean()) / (v.std() + 1e-8)\n",
    "\n",
    "    # ── Edges ─────────────────────────────────────────────────────────────\n",
    "    today = win[win['date'] == snap]\n",
    "\n",
    "    def make_clique_edges(groups: Dict[int, List[int]], weight_fn):\n",
    "        src, dst, w = [], [], []\n",
    "        for members in groups.values():\n",
    "            for i in members:\n",
    "                for j in members:\n",
    "                    if i != j:\n",
    "                        src.append(i); dst.append(j)\n",
    "                        w.append(weight_fn(len(members)))\n",
    "        return src, dst, w\n",
    "\n",
    "    pen_groups  = {}\n",
    "    bunk_groups = {}\n",
    "    for _, row in today.iterrows():\n",
    "        idx = cow_to_idx[row['cow_id']]\n",
    "        if 'pen_id'  in today.columns: pen_groups.setdefault(int(row['pen_id']),  []).append(idx)\n",
    "        if 'bunk_id' in today.columns: bunk_groups.setdefault(int(row['bunk_id']), []).append(idx)\n",
    "\n",
    "    ps, pd_, pw = make_clique_edges(pen_groups,  lambda n: 1.0)\n",
    "    bs, bd, bw  = make_clique_edges(bunk_groups, lambda n: min(n / 5.0, 3.0))\n",
    "\n",
    "    all_src = ps + bs\n",
    "    all_dst = pd_ + bd\n",
    "    all_w   = pw + bw\n",
    "\n",
    "    if all_src:\n",
    "        edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n",
    "        edge_attr  = torch.tensor(all_w, dtype=torch.float).unsqueeze(1)\n",
    "    else:\n",
    "        edge_index = torch.zeros((2, 0), dtype=torch.long)\n",
    "        edge_attr  = torch.zeros((0, 1), dtype=torch.float)\n",
    "\n",
    "    data = Data(edge_index=edge_index, edge_attr=edge_attr)\n",
    "    data.x_seq     = torch.tensor(x_seq, dtype=torch.float)\n",
    "    data.num_nodes = N\n",
    "    data.cow_ids   = cows\n",
    "    data.date      = str(snap.date())\n",
    "    return data\n",
    "\n",
    "\n",
    "# Smoke test\n",
    "g = build_graph(FARM_DF, FARM_DF['date'].max())\n",
    "print(f'Graph: {g.num_nodes} nodes  {g.edge_index.shape[1]} edges')\n",
    "print(f'x_seq: {g.x_seq.shape}   (N, T, F)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_contact_graph(graph: Data, title='Herd Contact Graph'):\n    G = nx.Graph()\n    G.add_nodes_from(range(graph.num_nodes))\n    ei = graph.edge_index.t().numpy()\n    ea = graph.edge_attr.squeeze(-1).numpy()\n    for k, (i, j) in enumerate(ei):\n        G.add_edge(int(i), int(j), weight=float(ea[k]) if k < len(ea) else 1.0)\n\n    pen_c = ['#2E5E1E','#C9983A','#5C3D1E','#6A9E48','#8C8070','#2C1A0E']\n    n     = graph.num_nodes\n    cols  = [pen_c[(c // (n // N_PENS)) % len(pen_c)] for c in range(n)]\n\n    pos = nx.spring_layout(G, seed=42, k=0.6)\n    fig, ax = plt.subplots(figsize=(12, 7))\n    ax.set_facecolor('#131008'); fig.patch.set_facecolor('#131008')\n\n    pen_e  = [(u,v) for u,v,d in G.edges(data=True) if abs(d['weight']-1.0)<0.01]\n    bunk_e = [(u,v) for u,v,d in G.edges(data=True) if abs(d['weight']-1.0)>0.01]\n\n    nx.draw_networkx_nodes(G, pos, node_color=cols,  node_size=200, ax=ax, alpha=0.9)\n    nx.draw_networkx_labels(G, pos, font_size=6, font_color='#F2EDE4', ax=ax)\n    nx.draw_networkx_edges(G, pos, edgelist=pen_e,  edge_color='#6A9E48', alpha=0.35, width=0.8,  ax=ax)\n    nx.draw_networkx_edges(G, pos, edgelist=bunk_e, edge_color='#C9983A', alpha=0.65, width=1.6,  ax=ax)\n\n    ax.legend(handles=[\n        mpatches.Patch(color='#6A9E48', label='Pen edge (w=1.0)'),\n        mpatches.Patch(color='#C9983A', label='Bunk co-visit edge'),\n    ], facecolor='#1E1A10', labelcolor='#F2EDE4', fontsize=9)\n    ax.set_title(title, color='#F2EDE4', fontsize=12)\n    ax.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nplot_contact_graph(g)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 03 · Synthetic Disease Injection\n",
    "\n",
    "The Wageningen dataset has no labeled disease outbreaks — it was used for calving prediction.\n",
    "We generate supervised labels by injecting disease events and propagating contagion through\n",
    "the contact graph using transmission rates from published literature:\n",
    "\n",
    "| Disease | Daily transmission p per contact | Source |\n",
    "|---------|----------------------------------|--------|\n",
    "| Mastitis | 0.15 | Zadoks et al. 2011, J Dairy Sci |\n",
    "| BRD | 0.25 | Snowder et al. 2006, J Anim Sci |\n",
    "| Lameness | 0.05 | Fourichon et al. 2003, J Dairy Sci |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "TRANSMISSION = {'mastitis': 0.15, 'brd': 0.25, 'lameness': 0.05}\nBACKGROUND   = {'mastitis': 0.008, 'brd': 0.005, 'lameness': 0.006}\n\n\ndef inject_disease(graph: Data, disease: str, n_seeds: int = 1,\n                   rng: Optional[np.random.Generator] = None) -> torch.Tensor:\n    \"\"\"\n    Inject a single disease event and propagate for 2 rounds (= 48 h).\n    Returns binary label tensor [N] — sick at T+48h.\n    \"\"\"\n    if rng is None:\n        rng = np.random.default_rng()\n    N   = graph.num_nodes\n    ei  = graph.edge_index.numpy()           # [2, E]\n    ew  = graph.edge_attr.squeeze(-1).numpy() # [E]\n    p   = TRANSMISSION[disease]\n\n    labels = (rng.random(N) < BACKGROUND[disease]).astype(int)\n    if n_seeds > 0:\n        labels[rng.choice(N, size=min(n_seeds, N), replace=False)] = 1\n\n    for _ in range(2):                      # 2 rounds = T+48h\n        new = labels.copy()\n        for k in range(ei.shape[1]):\n            src, dst = ei[0, k], ei[1, k]\n            if labels[src] == 1 and new[dst] == 0:\n                if rng.random() < min(p * float(ew[k]), 1.0):\n                    new[dst] = 1\n        labels = new\n    return torch.tensor(labels, dtype=torch.float)\n\n\ndef make_labels(graph: Data, rng=None) -> torch.Tensor:\n    \"\"\"[N, 3] label tensor — one column per disease.\"\"\"\n    if rng is None: rng = np.random.default_rng()\n    return torch.stack([\n        inject_disease(graph, d, n_seeds=int(rng.integers(0, 3)), rng=rng)\n        for d in DISEASES\n    ], dim=1)\n\n\ndemo_y = make_labels(g, rng=np.random.default_rng(42))\nprint('Label shape:', demo_y.shape)\nfor i, d in enumerate(DISEASES):\n    pos = demo_y[:, i].sum().int().item()\n    print(f'  {d:10s}: {pos}/{g.num_nodes} positive')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Build the full labelled dataset ────────────────────────────────────\n",
    "# n_runs injection runs per snapshot date → ~580 labelled graphs (>500 target)\n",
    "\n",
    "def build_dataset(farm_df: pd.DataFrame, n_runs: int = 7,\n",
    "                  window: int = WINDOW_DAYS) -> List[Data]:\n",
    "    dates   = sorted(farm_df['date'].unique())[window:]\n",
    "    dataset = []\n",
    "    rng     = np.random.default_rng(42)\n",
    "    print(f'Building {len(dates)} × {n_runs} = {len(dates)*n_runs} labelled snapshots…')\n",
    "\n",
    "    for i, date in enumerate(dates):\n",
    "        base = build_graph(farm_df, date, window)\n",
    "        for _ in range(n_runs):\n",
    "            g = base.clone()\n",
    "            g.y = make_labels(g, rng)\n",
    "            dataset.append(g)\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f'  {i+1}/{len(dates)}')\n",
    "\n",
    "    print(f'Done — {len(dataset)} graphs')\n",
    "    return dataset\n",
    "\n",
    "\n",
    "DATASET = build_dataset(FARM_DF)\n",
    "torch.save(DATASET, DATA_DIR / 'dataset.pt')\n",
    "print(f'Saved → data/dataset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 04 · TauronGNN — GraphSAGE + GRU\n",
    "\n",
    "```\n",
    "x_seq  [N, T=7, F=9]\n",
    "         │\n",
    "       GRU  hidden=128          temporal encoding of each cow's 7-day window\n",
    "         │\n",
    "       h  [N, 128]\n",
    "         │\n",
    "       SAGEConv  (128→128)      hop 1 — aggregate 1-hop neighbours\n",
    "       SAGEConv  (128→128)      hop 2 — aggregate 2-hop neighbours\n",
    "         │\n",
    "       Linear (128→3) + Sigmoid\n",
    "         │\n",
    "       risk  [N, 3]             mastitis | BRD | lameness  — T+48h\n",
    "```\n",
    "\n",
    "Same graph, same weights — disease specialisation lives in the three output neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "class TauronGNN(nn.Module):\n    def __init__(self,\n                 n_features: int = N_FEATURES,\n                 window: int = WINDOW_DAYS,\n                 hidden: int = 128,\n                 n_diseases: int = 3,\n                 dropout: float = 0.3):\n        super().__init__()\n        # Temporal encoder\n        self.gru = nn.GRU(input_size=n_features, hidden_size=hidden,\n                          num_layers=1, batch_first=True)\n        # Graph encoder — 2 SAGE layers = 2-hop neighbourhood\n        self.sage1 = SAGEConv(hidden, hidden)\n        self.sage2 = SAGEConv(hidden, hidden)\n        self.norm1 = nn.LayerNorm(hidden)\n        self.norm2 = nn.LayerNorm(hidden)\n        self.drop  = nn.Dropout(dropout)\n        # Three-head decoder — one neuron per disease\n        self.decoder = nn.Linear(hidden, n_diseases)\n\n    def forward(self, data: Data) -> torch.Tensor:\n        # 1. Temporal: GRU over 7-day window → last hidden state\n        _, h_n = self.gru(data.x_seq)          # h_n: [1, N, H]\n        h = h_n.squeeze(0)                     # [N, H]\n\n        # 2. Graph: 2-hop message passing\n        h = self.drop(F.relu(self.norm1(self.sage1(h, data.edge_index))))\n        h = self.drop(F.relu(self.norm2(self.sage2(h, data.edge_index))))\n\n        # 3. Raw logits [N, 3] — sigmoid applied in predict() / explain_cow()\n        return self.decoder(h)\n\n\nmodel = TauronGNN().to(DEVICE)\nsample = DATASET[0].to(DEVICE)\nwith torch.no_grad():\n    out = torch.sigmoid(model(sample))\nprint(f'Output shape : {out.shape}   (expect [{sample.num_nodes}, 3])')\nprint(f'Parameters   : {sum(p.numel() for p in model.parameters()):,}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 05 · Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 80/20 train/val split on graph snapshots\nidx = list(range(len(DATASET)))\ntrain_idx, val_idx = train_test_split(idx, test_size=0.2, random_state=42)\nTRAIN = [DATASET[i] for i in train_idx]\nVAL   = [DATASET[i] for i in val_idx]\nprint(f'Train: {len(TRAIN)}   Val: {len(VAL)}')\n\n# Positive-class weights to handle imbalance — passed to BCEWithLogitsLoss\nall_y      = torch.cat([g.y for g in DATASET])\npos_frac   = all_y.mean(0).clamp(1e-4, 1-1e-4)\npos_weight = ((1 - pos_frac) / pos_frac).to(DEVICE)\ncriterion  = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n\n\ndef train_epoch(model, graphs, opt):\n    model.train()\n    total = 0.0\n    random.shuffle(graphs)\n    for g in graphs:\n        g = g.to(DEVICE)\n        opt.zero_grad()\n        loss = criterion(model(g), g.y.to(DEVICE))\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n        opt.step()\n        total += loss.item()\n    return total / len(graphs)\n\n\n@torch.no_grad()\ndef evaluate(model, graphs):\n    model.eval()\n    preds, trues, loss_sum = [], [], 0.0\n    for g in graphs:\n        g = g.to(DEVICE)\n        logits = model(g)\n        loss_sum += criterion(logits, g.y.to(DEVICE)).item()\n        preds.append(logits.cpu()); trues.append(g.y.cpu())\n\n    P = torch.cat(preds).numpy()   # logits — AUROC is rank-invariant so no sigmoid needed\n    T = torch.cat(trues).numpy()\n    aurocs = {}\n    for i, d in enumerate(DISEASES):\n        yt, yp = T[:, i], P[:, i]\n        aurocs[d] = roc_auc_score(yt, yp) if yt.sum() > 0 and (1-yt).sum() > 0 else float('nan')\n    return loss_sum / len(graphs), aurocs, P, T\n\n\nprint('Training helpers ready.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 50\n",
    "model    = TauronGNN().to(DEVICE)\n",
    "opt      = Adam(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "sched    = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=N_EPOCHS)\n",
    "\n",
    "history    = {'train_loss': [], 'val_loss': [], 'auroc': {d: [] for d in DISEASES}}\n",
    "best_auroc = -1\n",
    "\n",
    "for epoch in range(1, N_EPOCHS + 1):\n",
    "    tl = train_epoch(model, TRAIN, opt)\n",
    "    vl, aurocs, _, _ = evaluate(model, VAL)\n",
    "    sched.step()\n",
    "\n",
    "    history['train_loss'].append(tl)\n",
    "    history['val_loss'].append(vl)\n",
    "    mean_a = np.nanmean(list(aurocs.values()))\n",
    "    for d in DISEASES: history['auroc'][d].append(aurocs[d])\n",
    "\n",
    "    if mean_a > best_auroc:\n",
    "        best_auroc = mean_a\n",
    "        torch.save(model.state_dict(), MODEL_DIR / 'tauron_model.pt')\n",
    "\n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        astr = '  '.join(f'{d[:3].upper()} {aurocs[d]:.3f}' for d in DISEASES)\n",
    "        print(f'ep {epoch:3d}  train {tl:.4f}  val {vl:.4f}  [{astr}]')\n",
    "\n",
    "print(f'\\nBest mean AUROC: {best_auroc:.4f}')\n",
    "print(f'Checkpoint → models/tauron_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training curves\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(13, 4), facecolor='#131008')\n",
    "for ax in (ax1, ax2):\n",
    "    ax.set_facecolor('#1E1A10')\n",
    "    [s.set_edgecolor('#3a3020') for s in ax.spines.values()]\n",
    "    ax.tick_params(colors='#8C8070')\n",
    "\n",
    "eps = range(1, N_EPOCHS + 1)\n",
    "ax1.plot(eps, history['train_loss'], color='#6A9E48', lw=1.5, label='Train')\n",
    "ax1.plot(eps, history['val_loss'],   color='#C9983A', lw=1.5, ls='--', label='Val')\n",
    "ax1.set_title('BCE Loss', color='#F2EDE4')\n",
    "ax1.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "dc = {'mastitis': '#6A9E48', 'brd': '#C9983A', 'lameness': '#8C8070'}\n",
    "for d in DISEASES:\n",
    "    ax2.plot(eps, history['auroc'][d], color=dc[d], lw=1.5, label=d.title())\n",
    "ax2.axhline(0.5, color='#3a3020', ls=':', lw=0.8)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.set_title('AUROC per Disease', color='#F2EDE4')\n",
    "ax2.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR / 'training_curves.png', dpi=150, bbox_inches='tight', facecolor='#131008')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 06 · Evaluation & Tier Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(MODEL_DIR / 'tauron_model.pt', map_location=DEVICE))\n",
    "_, final_aurocs, val_preds, val_trues = evaluate(model, VAL)\n",
    "\n",
    "print('Final Validation AUROC')\n",
    "for d in DISEASES:\n",
    "    ap = average_precision_score(val_trues[:, DISEASES.index(d)],\n",
    "                                 val_preds[:, DISEASES.index(d)])\n",
    "    print(f'  {d:10s}  AUROC {final_aurocs[d]:.4f}  AP {ap:.4f}')\n",
    "print(f'  Mean AUROC: {np.nanmean(list(final_aurocs.values())):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curves\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4), facecolor='#131008')\n",
    "for i, (d, ax) in enumerate(zip(DISEASES, axes)):\n",
    "    ax.set_facecolor('#1E1A10')\n",
    "    [s.set_edgecolor('#3a3020') for s in ax.spines.values()]\n",
    "    ax.tick_params(colors='#8C8070')\n",
    "    yt, yp = val_trues[:, i], val_preds[:, i]\n",
    "    if yt.sum() > 0:\n",
    "        fpr, tpr, _ = roc_curve(yt, yp)\n",
    "        ax.plot(fpr, tpr, color=list(dc.values())[i], lw=2,\n",
    "                label=f'AUC {final_aurocs[d]:.3f}')\n",
    "    ax.plot([0,1],[0,1], color='#3a3020', ls=':', lw=0.8)\n",
    "    ax.set_title(d.title(), color='#F2EDE4')\n",
    "    ax.set_xlabel('FPR', color='#8C8070')\n",
    "    ax.set_ylabel('TPR', color='#8C8070')\n",
    "    ax.legend(facecolor='#131008', labelcolor='#F2EDE4')\n",
    "\n",
    "plt.suptitle('ROC Curves — TauronGNN', color='#F2EDE4')\n",
    "plt.tight_layout()\n",
    "plt.savefig(DATA_DIR / 'roc_curves.png', dpi=150, bbox_inches='tight', facecolor='#131008')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Risk score calibration across data tiers ─────────────────────────────\n",
    "# Simulate lower tiers by zeroing features unavailable without wearables/AMS\n",
    "\n",
    "TIER_FEATURES = {\n",
    "    1: ['milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk'],\n",
    "    2: ['milk_yield_kg', 'health_event', 'feeding_visits', 'days_in_milk',\n",
    "        'feeding_min'],\n",
    "    3: SENSOR_FEATURES,   # all features including Wageningen ear-tag signals\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_tier(model, graphs, tier):\n",
    "    allowed = TIER_FEATURES[tier]\n",
    "    keep    = [SENSOR_FEATURES.index(f) for f in allowed if f in SENSOR_FEATURES]\n",
    "    mask    = torch.zeros(N_FEATURES)\n",
    "    mask[keep] = 1.0\n",
    "\n",
    "    tiered = []\n",
    "    for g in graphs:\n",
    "        g2 = g.clone()\n",
    "        g2.x_seq = g.x_seq * mask\n",
    "        tiered.append(g2)\n",
    "    _, aurocs, _, _ = evaluate(model, tiered)\n",
    "    return aurocs\n",
    "\n",
    "\n",
    "tier_aurocs = {t: eval_tier(model, VAL[:40], t) for t in [1, 2, 3]}\n",
    "\n",
    "print(f'{\"\":8s}  {\"mastitis\":>10}  {\"brd\":>8}  {\"lameness\":>10}  {\"mean\":>6}')\n",
    "for t in [1, 2, 3]:\n",
    "    r = tier_aurocs[t]\n",
    "    m = np.nanmean(list(r.values()))\n",
    "    print(f'Tier {t}    {r[\"mastitis\"]:>10.3f}  {r[\"brd\"]:>8.3f}  {r[\"lameness\"]:>10.3f}  {m:>6.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 07 · Inference + XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "@torch.no_grad()\ndef predict(graph: Data) -> Dict:\n    \"\"\"cow_id → {mastitis, brd, lameness} risk scores in [0, 1].\"\"\"\n    model.eval()\n    risk = torch.sigmoid(model(graph.to(DEVICE))).cpu()\n    return {\n        cid: {d: round(float(risk[i, j]), 3) for j, d in enumerate(DISEASES)}\n        for i, cid in enumerate(graph.cow_ids)\n    }\n\n\ndef explain_cow(graph: Data, cow_idx: int) -> Dict:\n    \"\"\"\n    Gradient-based feature importance + pen-mate context.\n    Returns structured JSON ready for the Claude API alert prompt.\n    \"\"\"\n    model.eval()\n\n    # ── Gradient attribution ───────────────────────────────────────────────\n    g = graph.clone().to(DEVICE)\n    g.x_seq.requires_grad_(True)\n    risk = torch.sigmoid(model(g))[cow_idx]   # [3] probs — sigmoid for backprop\n    dom  = risk.argmax().item()\n    risk[dom].backward()\n\n    grad      = g.x_seq.grad[cow_idx].abs().mean(0).cpu().numpy()  # [F]\n    total     = grad.sum() + 1e-8\n    ranked    = sorted(range(N_FEATURES), key=lambda i: -grad[i])\n    top_feats = [\n        {'feature': SENSOR_FEATURES[i], 'importance': round(float(grad[i] / total), 3)}\n        for i in ranked[:3]\n    ]\n\n    # ── Full herd risks — single forward pass ─────────────────────────────\n    with torch.no_grad():\n        all_risk_herd = torch.sigmoid(model(graph.to(DEVICE))).cpu()  # [N, 3]\n    all_risk = all_risk_herd[cow_idx]\n\n    # ── Contact edges ──────────────────────────────────────────────────────\n    ei = graph.edge_index.cpu().numpy()\n    ea = graph.edge_attr.squeeze(-1).cpu().numpy()\n    connected = [(k, int(ei[1, k])) for k in range(ei.shape[1]) if ei[0, k] == cow_idx]\n\n    top_edge = None\n    if connected:\n        k, nbr   = max(connected, key=lambda x: float(ea[x[0]]) if x[0] < len(ea) else 0)\n        top_edge = {'neighbour_cow': graph.cow_ids[nbr],\n                    'edge_weight':   round(float(ea[k]), 2)}\n\n    # ── Pen-mate risks (deduplicated, threshold > 0.3) ────────────────────\n    seen = set()\n    pen_mates_elevated = []\n    for _, nbr_idx in connected:\n        nbr_cid = graph.cow_ids[nbr_idx]\n        if nbr_cid in seen:\n            continue\n        seen.add(nbr_cid)\n        nbr_r = round(float(all_risk_herd[nbr_idx, dom]), 3)\n        if nbr_r > 0.3:\n            pen_mates_elevated.append({'cow_id': nbr_cid, 'risk': nbr_r})\n\n    return {\n        'cow_id':             f'#{graph.cow_ids[cow_idx]}',\n        'date':               graph.date,\n        'risk':               round(float(all_risk[dom]), 3),\n        'dominant_disease':   DISEASES[dom],\n        'all_risks':          {d: round(float(all_risk[i]), 3) for i, d in enumerate(DISEASES)},\n        'top_feature':        top_feats[0]['feature'],\n        'top_features':       top_feats,\n        'top_edge':           top_edge,\n        'pen_mates_elevated': pen_mates_elevated,\n    }\n\n\n# Demo on latest snapshot\nlatest = build_graph(FARM_DF, FARM_DF['date'].max())\nscores = predict(latest)\nranked = sorted(scores.items(), key=lambda x: max(x[1].values()), reverse=True)\n\nprint('Top 5 at-risk cows:')\nfor cid, r in ranked[:5]:\n    best = max(r, key=r.get)\n    print(f'  Cow #{cid:2d}  {best:10s}  {r[best]:.3f}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XAI output for top cow\n",
    "top_id  = ranked[0][0]\n",
    "top_idx = latest.cow_ids.index(top_id)\n",
    "xai     = explain_cow(latest, top_idx)\n",
    "print(json.dumps(xai, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 08 · Demo — Staged Event: Cow #47, Mastitis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stage_demo(farm_df: pd.DataFrame, patient_zero: int = 47,\n",
    "               event_date: str = '2026-01-13') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Inject a realistic 3-day prodromal signal for Cow #patient_zero\n",
    "    matching known mastitis sensor patterns from the Wageningen paper:\n",
    "    - activity drops before clinical onset\n",
    "    - ear temperature rises ~24h prior\n",
    "    - milk yield falls sharply on event day\n",
    "    \"\"\"\n",
    "    df   = farm_df.copy()\n",
    "    evd  = pd.Timestamp(event_date)\n",
    "\n",
    "    prodromes = [\n",
    "        (3, dict(activity=0.95, rumination_min=0.97, ear_temp_c=lambda x: x+0.2)),\n",
    "        (2, dict(activity=0.88, rumination_min=0.92, ear_temp_c=lambda x: x+0.5,\n",
    "                 milk_yield_kg=0.94)),\n",
    "        (1, dict(activity=0.78, rumination_min=0.85, ear_temp_c=lambda x: x+0.9,\n",
    "                 milk_yield_kg=0.88)),\n",
    "    ]\n",
    "    for delta, changes in prodromes:\n",
    "        mask = (df['cow_id'] == patient_zero) & (df['date'] == evd - timedelta(days=delta))\n",
    "        for col, fn in changes.items():\n",
    "            if mask.any() and col in df.columns:\n",
    "                df.loc[mask, col] = df.loc[mask, col].apply(\n",
    "                    fn if callable(fn) else lambda x, f=fn: x * f\n",
    "                )\n",
    "\n",
    "    # Event day — acute mastitis profile\n",
    "    mask = (df['cow_id'] == patient_zero) & (df['date'] == evd)\n",
    "    if mask.any():\n",
    "        df.loc[mask, 'milk_yield_kg']  *= 0.78\n",
    "        df.loc[mask, 'ear_temp_c']      = 39.8\n",
    "        df.loc[mask, 'activity']        *= 0.65\n",
    "        df.loc[mask, 'rumination_min'] *= 0.70\n",
    "        df.loc[mask, 'health_event']    = 1\n",
    "    return df\n",
    "\n",
    "\n",
    "# Extend to demo date and inject\n",
    "extra = pd.date_range('2025-12-30', '2026-01-15')\n",
    "rows  = []\n",
    "for d in extra:\n",
    "    for cow in range(N_COWS):\n",
    "        r = FARM_DF[FARM_DF['cow_id'] == cow].iloc[-1].copy()\n",
    "        r['date'] = d\n",
    "        r['milk_yield_kg'] += np.random.normal(0, 0.4)\n",
    "        rows.append(r)\n",
    "\n",
    "DEMO_DF    = pd.concat([FARM_DF, pd.DataFrame(rows)], ignore_index=True)\n",
    "DEMO_DF    = stage_demo(DEMO_DF)\n",
    "demo_graph = build_graph(DEMO_DF, '2026-01-13')\n",
    "demo_scores = predict(demo_graph)\n",
    "\n",
    "print('Cow #47 risks on 2026-01-13:')\n",
    "print(json.dumps(demo_scores[47], indent=2))\n",
    "\n",
    "xai47 = explain_cow(demo_graph, demo_graph.cow_ids.index(47))\n",
    "print('\\nXAI:')\n",
    "print(json.dumps(xai47, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Risk herd map — Cow #47 highlighted, transmission edges glowing\nfrom matplotlib.colors import LinearSegmentedColormap\n\ndef plot_risk_map(graph, scores, highlight=47, title='Herd Risk Map'):\n    G    = nx.Graph()\n    G.add_nodes_from(graph.cow_ids)\n    ei   = graph.edge_index.t().numpy()\n    ea   = graph.edge_attr.squeeze(-1).numpy()\n    i2id = {i: c for i, c in enumerate(graph.cow_ids)}\n    for k, (i, j) in enumerate(ei):\n        G.add_edge(i2id[i], i2id[j], weight=float(ea[k]) if k < len(ea) else 1.0)\n\n    cmap = LinearSegmentedColormap.from_list('risk', ['#2E5E1E','#C9983A','#8B0000'])\n    risk = {cid: max(r.values()) for cid, r in scores.items()}\n    cols  = [cmap(risk.get(c, 0)) for c in G.nodes]\n    sizes = [700 if c == highlight else 140 for c in G.nodes]\n\n    pos  = nx.spring_layout(G, seed=42, k=0.55)\n    fig, ax = plt.subplots(figsize=(13, 8))\n    ax.set_facecolor('#131008'); fig.patch.set_facecolor('#131008')\n\n    nbrs  = list(G.neighbors(highlight))\n    norm_e = [(u,v) for u,v in G.edges if highlight not in (u,v)]\n    glow_e = [(highlight, v) for v in nbrs]\n\n    nx.draw_networkx_edges(G, pos, edgelist=norm_e, edge_color='#2a2015', width=0.6, ax=ax)\n    nx.draw_networkx_edges(G, pos, edgelist=glow_e, edge_color='#C9983A', width=2.2, alpha=0.85, ax=ax)\n    nx.draw_networkx_nodes(G, pos, node_color=cols, node_size=sizes, ax=ax, alpha=0.92)\n    nx.draw_networkx_labels(G, pos, font_size=5, font_color='#F2EDE4', ax=ax)\n\n    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(0, 1))\n    sm.set_array([])\n    cb = plt.colorbar(sm, ax=ax, fraction=0.024, pad=0.02)\n    cb.set_label('Max Risk Score', color='#8C8070')\n    cb.ax.yaxis.set_tick_params(color='#8C8070')\n    plt.setp(cb.ax.yaxis.get_ticklabels(), color='#8C8070')\n\n    ax.set_title(title, color='#F2EDE4', fontsize=12)\n    ax.axis('off')\n    plt.tight_layout()\n    plt.savefig(DATA_DIR / 'demo_risk_graph.png', dpi=150,\n                bbox_inches='tight', facecolor='#131008')\n    plt.show()\n\nplot_risk_map(demo_graph, demo_scores,\n              title='Herd Risk Map · 2026-01-13 · Cow #47 Mastitis Event')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 09 · FastAPI Backend"
   ]
  },
  {
   "cell_type": "code",
   "source": "\n# ── Write tauron_pipeline.py — importable module for the API ─────────────\n# Contains all pipeline functions so api.py can import them directly.\n\nPIPELINE_CODE = '''\nimport os, json, random, warnings\nfrom pathlib import Path\nfrom datetime import datetime, timedelta\nfrom typing import Dict, List, Optional\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch_geometric.data import Data\nfrom torch_geometric.nn import SAGEConv\n\nwarnings.filterwarnings(\"ignore\")\n\n# ── Constants ─────────────────────────────────────────────────────────────\nDEVICE      = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\nN_COWS      = 60\nN_PENS      = 6\nN_BUNKS     = 4\nN_DAYS      = 90\nSTART       = datetime(2025, 10, 1)\nWINDOW_DAYS = 7\nDISEASES    = [\"mastitis\", \"brd\", \"lameness\"]\n\nSENSOR_FEATURES = [\n    \"activity\", \"highly_active\", \"rumination_min\", \"feeding_min\", \"ear_temp_c\",\n    \"milk_yield_kg\", \"health_event\", \"feeding_visits\", \"days_in_milk\",\n]\nN_FEATURES = len(SENSOR_FEATURES)\n\nTRANSMISSION = {\"mastitis\": 0.15, \"brd\": 0.25, \"lameness\": 0.05}\nBACKGROUND   = {\"mastitis\": 0.008, \"brd\": 0.005, \"lameness\": 0.006}\n\n\n# ── Farm generator ────────────────────────────────────────────────────────\ndef generate_farm(n_cows=N_COWS, n_pens=N_PENS, n_bunks=N_BUNKS,\n                  n_days=N_DAYS, seed=42) -> pd.DataFrame:\n    rng        = np.random.default_rng(seed)\n    pen_assign = {i: i // (n_cows // n_pens) for i in range(n_cows)}\n    bunk_pref  = {i: rng.integers(0, n_bunks) for i in range(n_cows)}\n    dim_base   = {i: int(rng.integers(5, 300)) for i in range(n_cows)}\n    base_yield = {i: float(rng.normal(28, 4).clip(18, 45)) for i in range(n_cows)}\n    rows = []\n    for day in range(n_days):\n        date = START + timedelta(days=day)\n        for cow in range(n_cows):\n            bunk = bunk_pref[cow] if rng.random() > 0.2 else rng.integers(0, n_bunks)\n            rows.append(dict(\n                cow_id=cow, date=date,\n                pen_id=pen_assign[cow], bunk_id=int(bunk),\n                activity=float(rng.normal(450, 80).clip(200, 800)),\n                highly_active=float(rng.normal(2.5, 0.8).clip(0, 8)),\n                rumination_min=float(rng.normal(480, 45).clip(300, 620)),\n                feeding_min=float(rng.normal(210, 35).clip(100, 360)),\n                ear_temp_c=float(rng.normal(38.5, 0.3).clip(37.0, 40.5)),\n                milk_yield_kg=float(rng.normal(base_yield[cow], 1.5).clip(10, 50)),\n                health_event=int(rng.random() < 0.01),\n                feeding_visits=int(rng.integers(3, 10)),\n                days_in_milk=dim_base[cow] + day,\n            ))\n    return pd.DataFrame(rows)\n\n\n# ── Graph builder ─────────────────────────────────────────────────────────\ndef build_graph(farm_df: pd.DataFrame, snapshot_date, window: int = WINDOW_DAYS) -> Data:\n    snap  = pd.Timestamp(snapshot_date)\n    start = snap - timedelta(days=window - 1)\n    win   = farm_df[(farm_df[\"date\"] >= start) & (farm_df[\"date\"] <= snap)].copy()\n\n    cows       = sorted(win[\"cow_id\"].unique())\n    cow_to_idx = {c: i for i, c in enumerate(cows)}\n    N          = len(cows)\n    dates      = sorted(win[\"date\"].unique())[-window:]\n    x_seq      = np.zeros((N, window, N_FEATURES), dtype=np.float32)\n\n    for t, d in enumerate(dates):\n        day = win[win[\"date\"] == d].set_index(\"cow_id\")\n        for f_idx, feat in enumerate(SENSOR_FEATURES):\n            if feat in day.columns:\n                for cow, idx in cow_to_idx.items():\n                    if cow in day.index:\n                        x_seq[idx, t, f_idx] = day.loc[cow, feat]\n\n    for f in range(N_FEATURES):\n        v = x_seq[:, :, f]\n        x_seq[:, :, f] = (v - v.mean()) / (v.std() + 1e-8)\n\n    today       = win[win[\"date\"] == snap]\n    pen_groups  = {}\n    bunk_groups = {}\n    for _, row in today.iterrows():\n        idx = cow_to_idx[row[\"cow_id\"]]\n        if \"pen_id\"  in today.columns: pen_groups.setdefault(int(row[\"pen_id\"]),  []).append(idx)\n        if \"bunk_id\" in today.columns: bunk_groups.setdefault(int(row[\"bunk_id\"]), []).append(idx)\n\n    def clique(groups, wfn):\n        s, d_, w = [], [], []\n        for m in groups.values():\n            for i in m:\n                for j in m:\n                    if i != j:\n                        s.append(i); d_.append(j); w.append(wfn(len(m)))\n        return s, d_, w\n\n    ps, pd_, pw = clique(pen_groups,  lambda n: 1.0)\n    bs, bd, bw  = clique(bunk_groups, lambda n: min(n / 5.0, 3.0))\n    all_src, all_dst, all_w = ps + bs, pd_ + bd, pw + bw\n\n    if all_src:\n        edge_index = torch.tensor([all_src, all_dst], dtype=torch.long)\n        edge_attr  = torch.tensor(all_w, dtype=torch.float).unsqueeze(1)\n    else:\n        edge_index = torch.zeros((2, 0), dtype=torch.long)\n        edge_attr  = torch.zeros((0, 1), dtype=torch.float)\n\n    data           = Data(edge_index=edge_index, edge_attr=edge_attr)\n    data.x_seq     = torch.tensor(x_seq, dtype=torch.float)\n    data.num_nodes = N\n    data.cow_ids   = cows\n    data.date      = str(snap.date())\n    return data\n\n\n# ── Model ─────────────────────────────────────────────────────────────────\nclass TauronGNN(nn.Module):\n    def __init__(self, n_features=N_FEATURES, hidden=128, n_diseases=3, dropout=0.3):\n        super().__init__()\n        self.gru     = nn.GRU(input_size=n_features, hidden_size=hidden,\n                              num_layers=1, batch_first=True)\n        self.sage1   = SAGEConv(hidden, hidden)\n        self.sage2   = SAGEConv(hidden, hidden)\n        self.norm1   = nn.LayerNorm(hidden)\n        self.norm2   = nn.LayerNorm(hidden)\n        self.drop    = nn.Dropout(dropout)\n        self.decoder = nn.Linear(hidden, n_diseases)\n\n    def forward(self, data: Data) -> torch.Tensor:\n        _, h_n = self.gru(data.x_seq)\n        h = h_n.squeeze(0)\n        h = self.drop(F.relu(self.norm1(self.sage1(h, data.edge_index))))\n        h = self.drop(F.relu(self.norm2(self.sage2(h, data.edge_index))))\n        return self.decoder(h)   # raw logits [N, 3]\n\n\n# Global model instance — loaded at API startup\nmodel = TauronGNN().to(DEVICE)\n\n\ndef load_model(ckpt: str = \"models/tauron_model.pt\"):\n    path = Path(ckpt)\n    if path.exists():\n        model.load_state_dict(torch.load(path, map_location=DEVICE))\n        model.eval()\n        print(f\"Loaded checkpoint {ckpt}\")\n    else:\n        print(f\"WARNING: {ckpt} not found — run the notebook to train first\")\n\n\n# ── Inference ─────────────────────────────────────────────────────────────\n@torch.no_grad()\ndef predict(graph: Data) -> Dict:\n    model.eval()\n    risk = torch.sigmoid(model(graph.to(DEVICE))).cpu()\n    return {\n        cid: {d: round(float(risk[i, j]), 3) for j, d in enumerate(DISEASES)}\n        for i, cid in enumerate(graph.cow_ids)\n    }\n\n\ndef explain_cow(graph: Data, cow_idx: int) -> Dict:\n    model.eval()\n    g = graph.clone().to(DEVICE)\n    g.x_seq.requires_grad_(True)\n    risk = torch.sigmoid(model(g))[cow_idx]\n    dom  = risk.argmax().item()\n    risk[dom].backward()\n\n    grad    = g.x_seq.grad[cow_idx].abs().mean(0).cpu().numpy()\n    total   = grad.sum() + 1e-8\n    ranked  = sorted(range(N_FEATURES), key=lambda i: -grad[i])\n    top_feats = [\n        {\"feature\": SENSOR_FEATURES[i], \"importance\": round(float(grad[i] / total), 3)}\n        for i in ranked[:3]\n    ]\n\n    with torch.no_grad():\n        all_risk_herd = torch.sigmoid(model(graph.to(DEVICE))).cpu()\n    all_risk = all_risk_herd[cow_idx]\n\n    ei = graph.edge_index.cpu().numpy()\n    ea = graph.edge_attr.squeeze(-1).cpu().numpy()\n    connected = [(k, int(ei[1, k])) for k in range(ei.shape[1]) if ei[0, k] == cow_idx]\n\n    top_edge = None\n    if connected:\n        k, nbr = max(connected, key=lambda x: float(ea[x[0]]) if x[0] < len(ea) else 0)\n        top_edge = {\"neighbour_cow\": graph.cow_ids[nbr],\n                    \"edge_weight\":   round(float(ea[k]), 2)}\n\n    seen, pen_mates_elevated = set(), []\n    for _, nbr_idx in connected:\n        nbr_cid = graph.cow_ids[nbr_idx]\n        if nbr_cid in seen: continue\n        seen.add(nbr_cid)\n        nbr_r = round(float(all_risk_herd[nbr_idx, dom]), 3)\n        if nbr_r > 0.3:\n            pen_mates_elevated.append({\"cow_id\": nbr_cid, \"risk\": nbr_r})\n\n    return {\n        \"cow_id\":             f\"#{graph.cow_ids[cow_idx]}\",\n        \"date\":               graph.date,\n        \"risk\":               round(float(all_risk[dom]), 3),\n        \"dominant_disease\":   DISEASES[dom],\n        \"all_risks\":          {d: round(float(all_risk[i]), 3) for i, d in enumerate(DISEASES)},\n        \"top_feature\":        top_feats[0][\"feature\"],\n        \"top_features\":       top_feats,\n        \"top_edge\":           top_edge,\n        \"pen_mates_elevated\": pen_mates_elevated,\n    }\n\n\n# ── Demo event ────────────────────────────────────────────────────────────\ndef stage_demo(farm_df: pd.DataFrame, patient_zero: int = 47,\n               event_date: str = \"2026-01-13\") -> pd.DataFrame:\n    df  = farm_df.copy()\n    evd = pd.Timestamp(event_date)\n    prodromes = [\n        (3, {\"activity\": 0.95, \"rumination_min\": 0.97, \"ear_temp_c\": lambda x: x + 0.2}),\n        (2, {\"activity\": 0.88, \"rumination_min\": 0.92, \"ear_temp_c\": lambda x: x + 0.5,\n             \"milk_yield_kg\": 0.94}),\n        (1, {\"activity\": 0.78, \"rumination_min\": 0.85, \"ear_temp_c\": lambda x: x + 0.9,\n             \"milk_yield_kg\": 0.88}),\n    ]\n    for delta, changes in prodromes:\n        mask = (df[\"cow_id\"] == patient_zero) & (df[\"date\"] == evd - timedelta(days=delta))\n        for col, fn in changes.items():\n            if mask.any() and col in df.columns:\n                df.loc[mask, col] = df.loc[mask, col].apply(\n                    fn if callable(fn) else lambda x, f=fn: x * f\n                )\n    mask = (df[\"cow_id\"] == patient_zero) & (df[\"date\"] == evd)\n    if mask.any():\n        df.loc[mask, \"milk_yield_kg\"]  *= 0.78\n        df.loc[mask, \"ear_temp_c\"]      = 39.8\n        df.loc[mask, \"activity\"]       *= 0.65\n        df.loc[mask, \"rumination_min\"] *= 0.70\n        df.loc[mask, \"health_event\"]    = 1\n    return df\n'''\n\nPath('tauron_pipeline.py').write_text(PIPELINE_CODE.lstrip())\nprint('tauron_pipeline.py written — importable module for api.py')\n",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "\n# ── Write api.py ──────────────────────────────────────────────────────────\n# Imports all pipeline functions from tauron_pipeline.py (written above).\n# Run with: uvicorn api:app --reload\n\nAPI_CODE = '''\nimport os, io, json\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom pathlib import Path\nfrom typing import Optional\nfrom datetime import timedelta\n\nfrom fastapi import FastAPI, UploadFile, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nimport anthropic\n\nimport tauron_pipeline as tp\n\napp = FastAPI(title=\"Tauron\", version=\"1.0\")\napp.add_middleware(CORSMiddleware, allow_origins=[\"*\"],\n                   allow_methods=[\"*\"], allow_headers=[\"*\"])\n\n_graph  = None\n_scores = None\n\n\n@app.on_event(\"startup\")\ndef load():\n    global _graph, _scores\n\n    # Build demo farm with staged Cow #47 mastitis event\n    farm_df = tp.generate_farm()\n    rng     = np.random.default_rng(99)\n    extra   = pd.date_range(\"2025-12-30\", \"2026-01-15\")\n    rows    = []\n    for d in extra:\n        for cow in range(tp.N_COWS):\n            r = farm_df[farm_df[\"cow_id\"] == cow].iloc[-1].copy()\n            r[\"date\"]          = d\n            r[\"milk_yield_kg\"] = float(r[\"milk_yield_kg\"]) + rng.normal(0, 0.4)\n            rows.append(r)\n    demo_df = pd.concat([farm_df, pd.DataFrame(rows)], ignore_index=True)\n    demo_df = tp.stage_demo(demo_df)\n\n    tp.load_model(\"models/tauron_model.pt\")\n\n    _graph  = tp.build_graph(demo_df, \"2026-01-13\")\n    _scores = tp.predict(_graph)\n    print(f\"Tauron API ready — {len(_scores)} cows | demo date 2026-01-13\")\n\n\n@app.get(\"/herd\")\ndef herd():\n    if _scores is None:\n        raise HTTPException(503, \"model not loaded\")\n    ei = _graph.edge_index.t().tolist()\n    ew = _graph.edge_attr.squeeze(-1).tolist()\n    return {\n        \"cows\":  _scores,\n        \"edges\": [{\"src\": e[0], \"dst\": e[1], \"w\": w} for e, w in zip(ei, ew)],\n    }\n\n\n@app.get(\"/alert/{cow_id}\")\ndef alert(cow_id: int):\n    if _graph is None:\n        raise HTTPException(503, \"model not loaded\")\n    if cow_id not in _graph.cow_ids:\n        raise HTTPException(404, f\"cow {cow_id} not found\")\n    return tp.explain_cow(_graph, _graph.cow_ids.index(cow_id))\n\n\n@app.get(\"/explain/{cow_id}\")\ndef explain(cow_id: int):\n    if _graph is None:\n        raise HTTPException(503, \"model not loaded\")\n    if cow_id not in _graph.cow_ids:\n        raise HTTPException(404, f\"cow {cow_id} not found\")\n    xai    = tp.explain_cow(_graph, _graph.cow_ids.index(cow_id))\n    client = anthropic.Anthropic(api_key=os.environ[\"ANTHROPIC_API_KEY\"])\n    msg    = client.messages.create(\n        model=\"claude-sonnet-4-6\", max_tokens=120,\n        messages=[{\"role\": \"user\", \"content\":\n            f\"You are a dairy herd advisor. Write one plain-English action sentence \"\n            f\"a farmer can act on immediately based on this model output: {json.dumps(xai)}\"}]\n    )\n    return {\"cow_id\": f\"#{cow_id}\", \"alert\": msg.content[0].text, \"xai\": xai}\n\n\n@app.post(\"/api/ingest\")\nasync def ingest(file: Optional[UploadFile] = None, tier: int = 1):\n    if file is None:\n        raise HTTPException(400, \"provide a CSV file\")\n    df = pd.read_csv(io.StringIO((await file.read()).decode()))\n    return {\"status\": \"ok\", \"rows\": len(df), \"tier\": tier}\n'''\n\nPath('api.py').write_text(API_CODE.lstrip())\nprint('api.py written.')\nprint('Start: source venv/bin/activate && uvicorn api:app --reload')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Component | Output |\n",
    "|-----------|--------|\n",
    "| Wageningen-profile farm data | `data/farm_synthetic.csv` (swap for `data/wageningen.csv`) |\n",
    "| Contact graph builder | `build_graph(farm_df, date)` → PyG `Data` |\n",
    "| Synthetic disease labels | `inject_disease()` + `make_labels()` → 500+ snapshots → `data/dataset.pt` |\n",
    "| TauronGNN (GraphSAGE + GRU) | 128-dim hidden, 2-hop, 3-head decoder |\n",
    "| Training (50 epochs, BCE) | `models/tauron_model.pt` (best AUROC checkpoint) |\n",
    "| Evaluation | ROC + AUROC per disease, tier calibration table |\n",
    "| Inference + XAI | `predict()` + `explain_cow()` → structured JSON |\n",
    "| Demo event | Cow #47 mastitis, 2026-01-13, transmission glow |\n",
    "| FastAPI backend | `api.py` — `/herd`, `/alert/{id}`, `/explain/{id}`, `/api/ingest` |\n",
    "\n",
    "**To swap in the real Wageningen data:**\n",
    "1. Request data from C.J. Rutten via https://research.wur.nl/en/publications/sensor-data-on-cow-activity-rumination-and-ear-temperature-improv/\n",
    "2. Save as `data/wageningen.csv` with columns matching `WAGENINGEN_COLS`\n",
    "3. Re-run from Section 01 — `USE_REAL_DATA` flips automatically"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tauron ML",
   "language": "python",
   "name": "tauron"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}